# 第一章：搜索引擎及其技术架构

## 1.1 搜索引擎为何重要

- 1995年是搜索引擎商业公司发展的重要起点，其对应的背景是：互联网上的web站点数量首次超过100万，此时普通用户已经无法依赖手工浏览的方式来获得自己想要的信息。
- Google于1998年成立，以PageRank链接分析等新技术大幅度提高了搜索质量。



## 1.2 搜索引擎技术发展史

- 搜索引擎技术的发展：**分类目录-文本检索-链接分析-用户中心**

### 1.2.1 史前时代：分类目录的一代

- 这个时代也可以称为导航时代，Yahoo和国内hao123是这个时代的代表。这个方式靠纯人工收集整理给网站或者网页分类，这种方式可扩展性不强，绝大部分网站不能被收录。

### 1.2.2 第一代：文本检索的一代

- 采用经典的信息检索模型，比如布尔模型、向量空间模型、概率模型，来计算用户查询关键词和网页文本内容的相关程度。

### 1.2.3 第二代：链接分析的一代

- 这一代搜素引擎充分利用了网页之间的链接关系，并深入挖掘和利用了网页链接所代表的含义。
- 网页链接代表了一种推荐关系，所以通过链接分析可以在海量内容中找出重要的网页。这种重要性质本质上是对网页流行程度的一种衡量，因为被推荐次数多的网页其实代表了其具有流行性。搜索引擎通过结合网页流行性和内容相似性来改善搜索质量。
- Google率先提出并使用PageRank链接分析技术，并大获成功。目前几乎所有的商业搜索引擎都采取了链接分析技术。
- 链接分析能够有效改善搜索结果质量，但是这种搜索引擎并未考虑用户的个性化要求，只要输入的查询请求相同，所有用户都会获得相同的搜索结果。还有一些链接作弊方案导致搜索结果质量变差。

### 1.2.4 第三代：用户中心的一代

- 目前的搜索引擎大都可以归入第三代，即以理解用户需求为核心。
- 不通用户即使输入同一个关键词，但其目的也有可能不一样；即使同一个用户，输入相同的查询词，也会因为所在的时间和场合不通，需求有所变化。
- 所以目前的搜索引擎都致力于解决如下问题：如何能够理解用户发出的某个很短小的查询词背后包含的真正需求。
- 为了获取用户的真实需求，目前搜索引擎做了很多技术方面的尝试：比如利用用户发送查询词时的时间和地理位置信息；利用用户过去发出的查询词及相应的点击记录等历史信息等技术手段。



## 1.3 搜索引擎的三个目标

- **更全**：目前任意一个商业搜索引擎索引网页的覆盖范围都只占了互联网页面的一部分，可以通过提高网络爬虫相关技术来达到此目标。
- **更快**：索引相关技术、缓存等技术的提出都是直接为了达到此目的。还有其他间接为此服务的技术，比如分布式海量云储存平台。
- **更准**：这是最为关键的目标，无论是排序技术也好，链接分析技术也好，抑或是用户研究等技术，最终都是为了使搜索结果更加准确。如果做到更准能够构建核心竞争能力。



## 1.4 搜索引擎的三个核心问题

### 1.4.1 3个核心问题

1. 用户真正的需求是什么
2. 哪些信息是和用户需求真正相关的
3. 哪些信息是用户可以信赖的

### 1.4.2 与技术发展的关系

- 对于**分类目录式搜索引擎**，因为分目录内收录的网站是经过人工精心筛选的，所以具有很强的可信赖性，但是对于用户需求和相关性是不做考虑的，完全由用户自由浏览来确定。
- 对于**第一代文本检索式搜索引擎**，其重点关注的式查询关键词和网页内容的相关性。这种方式假定用户输入的关键词就是用户的真实需求，但是这种假设很难成立。另外，这种方式对信息的可信度也未做任何识别。
- 第二代**搜索引擎引入链接分析技术**，链接关系代表了一种推荐含义，而获得越多推荐的网页其链接分析得分越高，这其实是对网页可信度的度量表中。同时应用了文本检索模型来计算查询内容和网页内容的相关性，所以第二代搜索引擎是综合考虑了信息的相关性和可信性的，但是没有对用户需求做关注。
- 第三代搜索引擎的重点则是用户的真实需求，其他方面则兼顾了第二代搜索引擎的优点，即第三代搜索引擎同时考虑了3个核心问题。



## 1.5 搜索引擎的技术架构

- 从架构层面，搜索引擎需要能够对以百亿计的海量网页进行 **获取、储存、处理** 的能力，同时要保证搜索结果的质量。

![1556505560260](C:\Users\11101453\AppData\Roaming\Typora\typora-user-images\1556505560260.png)

- 当搜索引擎接收到用户的查询词后，首先需要对查询词进行分析，希望能够结合查询词和用户信息来正确推导用户的真正搜索意图。在此之后，首先在缓存种查找，搜索引擎的缓存系统储存了不同的查询意图对应的搜索结果，如果能够在缓存系统找到满足用户需求的信息，则可以直接将搜索结果返回给用户。如果储存在缓存的信息无法满足用户需求，搜索引擎需要调用“网页排序”模块功能，根据用户的查询实时计算哪些网页是满足用户信息需求的，并排序输出作为搜索结果。
- 在网页排序中最重要的两个参考因素中，一个是**内容相似性因素**，即哪些网页是和用户查询密切相关的；另外一个是**网页重要性因素**，即哪些网页是质量较好或者相对重要的，这点往往可以从链接分析的结果获得。





# 第二章：网络爬虫

## 2.4 抓取策略

### 2.4.1 宽度优先遍历策略（Breath First）

- **基本思路**：将新下载网页包含的链接直接追加到待抓取URL队列末尾。
- 这种方法并没有明确提出和使用网页重要衡量标准，知识机械地将新下载的网页抽取链接，并追加到待抓取URL队列中，以此安排URL的下载顺序。

### 2.4.2 非完全PageRank策略（Partial PageRank）

- **基本思路**：对于已经下载的网页，加上待抓取URL队列中的URL一起，形成网页集合，在此集合中记算PageRank计算，计算完成后，将待抓取URL队列里的网页按照PageRank得分由高到低排序，形成的序列就是爬虫接下来应该依次抓取的URL列表。这也是为何称之为”非完全PageRank“的原因。

### 2.4.3 OCIP策略(Online Page Importance Computation)

- 在算法开始之前，每个互联网页面都给与相同的“现金”（cash），每当下载了某个页面P后，P将自己的“现金”平均分配给页面中包含的链接页面，清空自己的“现金”。待抓取的URL则根据自己的现金排序，优先下载现金多的网页。
- OCIP从大的框架上与PageRank思路基本一致，区别在于：PageRank每次需要迭代计算，而OCIP策略不需要迭代过程，所以计算速度远远快于PageRank，适合实时计算使用。

### 2.4.4 大站优先策略

- **基本思路**：以网站为单位来衡量网页的重要性，对于待抓取URL队列中的网页，根据所属网站归类，如果哪个网站等待下载的页面多，则优先下载这些链接。
- 其本质思想倾向于优先下载大型网站，因为大型网站包含更多的页面，网页质量一般较高。



## 2.5 网页更新策略

### 2.5.1 历史参考策略

- 这种方法往往利用泊松过程来对网页的变化进行建模，根据每个网页过去的变动情况，利用模型预测将来何时内容会在此发生变化，以此来指导爬虫的抓取过程。

### 2.5.2 用户体验策略

- 这种更新策略以用户体验为核心，即使本地索引的网页内容是过时的，但是如果不影响用户体验，那么晚些更新这些过时的网页也未尝不可。
- 所以判断一个网页何时更新为好，取决于这个网页的内容变化所带来搜索质量的变化（往往采用搜索结果排名的变化来衡量），影响越大的网页，则应该越快更新。

### 2.5.3 聚类抽样策略

- 聚类抽样策略认为：网页具有一些属性，根据这些属性可以预测其更新周期，具有相似属性的网页，其更新周期也是类似的。为了计算某个类别的更新周期，只需对类别内网页进行采样，以这些被采样网页的更新周期作为类别内所有其他网页的更新周期。
- 与之前叙述的两种方法相比较，这种策略一方面无须为每个网页保存历史信息；另一方面，对于新网页，即使没有历史信息，也可以根据其所属类别来对其进行更新。
- 网页更新周期的属性特征：
  - 静态特征：页面的内容、图片数量、页面大小、链接深度、PageRank值等十几种
  - 动态特征：体验静态特征随着时间的变化情况，比如图片数量的变化情况、入链出链的变化情况。

> - 从爬虫设计角度讲，优秀的爬虫应该具备 **高性能，好的可扩展性、健壮性和友好性**。
> - 从用户体验角度考虑，对爬虫的工作效果评价标准包括：**抓取网页覆盖率、抓取网页时新性和抓取网页重要性**。
> - **抓取策略、网页更新策略、暗网抓取和分布式策略 **是爬虫系统至关重要的4个方面内容，基本决定了爬虫系统的质量和性能。





# 第三章：搜索引擎索引

## 3.1 索引基础

### 3.1.1 单词-文档矩阵

![1556522970406](C:\Users\11101453\AppData\Roaming\Typora\typora-user-images\1556522970406.png)

- 从纵向即文档这个维度来看，每列代表文档包含了哪些单词；从横向即单词这个维度来看，每行代表了哪些文档包含了某个单词。
- 搜索引擎的索引其实就是实现单词-文档矩阵的具体数据结构。可以有不同方式来实现上述概念模型，比如**倒排索引、签名文件、后缀树**等方式。倒排索引是单词到文档映射关系的最佳实现方式。

### 3.1.2 倒排索引基本概念

- **文档（Document）**：一般搜索引擎的处理对象是互联网网页，而文档这个概念要更宽泛些，代表以文本形式存在的存储对象。比如Word、PDF、HTML、XML，再比如一封邮件、一条微博也可以称之为文档。
- **文档集合（Document Collection）**：由若干文档构成的集合称为文档集合。比如海量的互联网网页或者说大量的电子邮件，都是文档集合的具体例子。
- **文档编号（Document ID）**：在搜索引擎内部，会为文档集合内每个文档赋予一个唯一的内部编号，以此编号来作为这个文档的唯一标识，方便内部处理。
- **单词编号（Word ID）**：与文档编号类似，搜索引擎内部以唯一的编号来表征某个单词，单词编号可以作为某个单词的唯一表征。
- **倒排索引（Inverted Index）**：倒排索引是实现单词-文档矩阵的一种具体存储形式。通过倒排索引，可以根据单词快速获取包含这个单词的文档列表。倒排索引主要由两个部分组成：单词词典和倒排文件。
- **单词词典（Lexicon）**：搜索引擎通常的索引单位就是单词，单词词典是由文档集合中出现过的所有单词构成的字符串集合，单词词典内每条索引项记载单词本身的一些信息及指向倒排列表的指针。
- **倒排列表（Posting List）**：<u>倒排列表记载了出现过某个单词的所有文档列表及单词在该文档中出现的位置信息</u>，每条记录称为一个倒排项（Posting）。根据倒排列表，即可获知哪些文档包含某个单词。
- **倒排文件（Inverted File）**：所有单词的倒排列表往往有序地存储在磁盘的某个文件里，这个文件即被称为倒排文件，倒排文件是存储倒排索引的物理文件。

### 3.1.3 倒排索引简单实例

![1556529586265](C:\Users\11101453\AppData\Roaming\Typora\typora-user-images\1556529586265.png)

![1556529608373](C:\Users\11101453\AppData\Roaming\Typora\typora-user-images\1556529608373.png)

![1556529630592](C:\Users\11101453\AppData\Roaming\Typora\typora-user-images\1556529630592.png)

- 如图3-6所示的索引系统除了记录文档编号和单词频率信息外，额外记载了两类信息，即每个单词对应的文档频率信息（对应图3-6的第3列）及单词在某个文档出现的位置信息。
- 以单词“拉斯”为例，其单词编号为8，文档频率为2，代表整个文档集合中有两个文档包含这个单词，对应的倒排列表为（3；1；<4>），（5；1；<4>），其含义为在文档3和文档5出现过这个单词，单词频率都为1，单词“拉斯”在两个文档中出现的位置都是4，即文档中第4个单词是“拉斯”。

![1556529772330](C:\Users\11101453\AppData\Roaming\Typora\typora-user-images\1556529772330.png)

- 有了这个索引系统，搜索引擎可以很方便地响应用户的查询，比如用户输入查询单词“Facebook”，搜索系统查找倒排索引，从中可以读出包含这个单词的文档，这些文档就是提供给用户的搜索结果，而利用单词频率信息、文档频率信息即可对这些候选搜索结果进行排序，计算文档和查询的相似性，按照相似性得分由高到低排序输出，此即为搜索系统的部分内部流程。



## 3.2 单词词典（Lexicon）

- 单词词典是倒排索引中非常重要的组成部分，它用来维护文档集合中出现过的所有单词的相关信息，同时用来记载某个单词对应的倒排列表在倒排文件中的位置信息。在支持搜索时，根据用户的查询词，去单词词典里面查询，就能够获得相应的倒排列表，并以此作为后续排序的基础。
- 为了提高定位单词的速度，需要高效的数据结构来对单词词典进行构建和查找，常用的数据结构包括**哈希加链表结构**和**树形词典结构**。

### 3.2.1 哈希加链表

### 3.3.2 树形结构



## 3.3 倒排列表（Posting List）

- 倒排列表用来记录由哪些文档包含了某个单词。一般在文档集合里会有很多文档包含某个单词，每个文档会记录文档编号（DocID），单词在这个文档中出现的次数（TF）及单词在文档中哪些位置出现过等信息，这样与一个文档相关的信息被称作倒排索引项（Posting），包含这个单词的一系列倒排索引项形成了列表结构，这就是某个单词对应的倒排列表。**即在文档集合中出现过的所有单词及其对应的倒排列表组成了倒排索引**

  ![1556587522396](C:\Users\11101453\AppData\Roaming\Typora\typora-user-images\1556587522396.png)



## 3.4 建立索引

### 3.4.1 两遍文档遍历法（2-Pass In-Memory Inversion）

- 第一遍文档遍历：第一遍扫描的主要目的是获得一些统计信息，并根据统计信息分配内存等资源，同时建立好单词相对应倒排列表在内存中的位置信息，即主要做哪些资源准备工作。
- 第二遍文档遍历：第二遍扫描开始真正建立每个单词的倒排列表信息，即对某个单词来说，获得包含这个单词的每个文档的文档ID，以及这个单词在文档中出现次数TF，这样就可以不断填充第一遍扫描所分配的内存空间。第二遍扫描结束，分配的内存空间正好被填充满，而每个单词用指针所指向的内存区域“片段”，其起始位置和终止位置之间的数据就是这个单词对应的倒排列表。

### 3.4.2 排序法（Sort-based Inversion）

### 3.4.3 归并法（Merge-based Inversion）

