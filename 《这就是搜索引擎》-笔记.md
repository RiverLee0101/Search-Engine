# 第一章：搜索引擎及其技术架构

## 1.1 搜索引擎为何重要

- 1995年是搜索引擎商业公司发展的重要起点，其对应的背景是：互联网上的web站点数量首次超过100万，此时普通用户已经无法依赖手工浏览的方式来获得自己想要的信息。
- Google于1998年成立，以PageRank链接分析等新技术大幅度提高了搜索质量。



## 1.2 搜索引擎技术发展史

- 搜索引擎技术的发展：**分类目录-文本检索-链接分析-用户中心**

### 1.2.1 史前时代：分类目录的一代

- 这个时代也可以称为导航时代，Yahoo和国内hao123是这个时代的代表。这个方式靠纯人工收集整理给网站或者网页分类，这种方式可扩展性不强，绝大部分网站不能被收录。

### 1.2.2 第一代：文本检索的一代

- 采用经典的信息检索模型，比如布尔模型、向量空间模型、概率模型，来计算用户查询关键词和网页文本内容的相关程度。

### 1.2.3 第二代：链接分析的一代

- 这一代搜素引擎充分利用了网页之间的链接关系，并深入挖掘和利用了网页链接所代表的含义。
- 网页链接代表了一种推荐关系，所以通过链接分析可以在海量内容中找出重要的网页。这种重要性质本质上是对网页流行程度的一种衡量，因为被推荐次数多的网页其实代表了其具有流行性。搜索引擎通过结合网页流行性和内容相似性来改善搜索质量。
- Google率先提出并使用PageRank链接分析技术，并大获成功。目前几乎所有的商业搜索引擎都采取了链接分析技术。
- 链接分析能够有效改善搜索结果质量，但是这种搜索引擎并未考虑用户的个性化要求，只要输入的查询请求相同，所有用户都会获得相同的搜索结果。还有一些链接作弊方案导致搜索结果质量变差。

### 1.2.4 第三代：用户中心的一代

- 目前的搜索引擎大都可以归入第三代，即以理解用户需求为核心。
- 不通用户即使输入同一个关键词，但其目的也有可能不一样；即使同一个用户，输入相同的查询词，也会因为所在的时间和场合不通，需求有所变化。
- 所以目前的搜索引擎都致力于解决如下问题：如何能够理解用户发出的某个很短小的查询词背后包含的真正需求。
- 为了获取用户的真实需求，目前搜索引擎做了很多技术方面的尝试：比如利用用户发送查询词时的时间和地理位置信息；利用用户过去发出的查询词及相应的点击记录等历史信息等技术手段。



## 1.3 搜索引擎的三个目标

- **更全**：目前任意一个商业搜索引擎索引网页的覆盖范围都只占了互联网页面的一部分，可以通过提高网络爬虫相关技术来达到此目标。
- **更快**：索引相关技术、缓存等技术的提出都是直接为了达到此目的。还有其他间接为此服务的技术，比如分布式海量云储存平台。
- **更准**：这是最为关键的目标，无论是排序技术也好，链接分析技术也好，抑或是用户研究等技术，最终都是为了使搜索结果更加准确。如果做到更准能够构建核心竞争能力。



## 1.4 搜索引擎的三个核心问题

### 1.4.1 3个核心问题

1. 用户真正的需求是什么
2. 哪些信息是和用户需求真正相关的
3. 哪些信息是用户可以信赖的

### 1.4.2 与技术发展的关系

- 对于**分类目录式搜索引擎**，因为分目录内收录的网站是经过人工精心筛选的，所以具有很强的可信赖性，但是对于用户需求和相关性是不做考虑的，完全由用户自由浏览来确定。
- 对于**第一代文本检索式搜索引擎**，其重点关注的式查询关键词和网页内容的相关性。这种方式假定用户输入的关键词就是用户的真实需求，但是这种假设很难成立。另外，这种方式对信息的可信度也未做任何识别。
- 第二代**搜索引擎引入链接分析技术**，链接关系代表了一种推荐含义，而获得越多推荐的网页其链接分析得分越高，这其实是对网页可信度的度量表中。同时应用了文本检索模型来计算查询内容和网页内容的相关性，所以第二代搜索引擎是综合考虑了信息的相关性和可信性的，但是没有对用户需求做关注。
- 第三代搜索引擎的重点则是用户的真实需求，其他方面则兼顾了第二代搜索引擎的优点，即第三代搜索引擎同时考虑了3个核心问题。



## 1.5 搜索引擎的技术架构

- 从架构层面，搜索引擎需要能够对以百亿计的海量网页进行 **获取、储存、处理** 的能力，同时要保证搜索结果的质量。

![1556505560260](C:\Users\11101453\AppData\Roaming\Typora\typora-user-images\1556505560260.png)

- 当搜索引擎接收到用户的查询词后，首先需要对查询词进行分析，希望能够结合查询词和用户信息来正确推导用户的真正搜索意图。在此之后，首先在缓存种查找，搜索引擎的缓存系统储存了不同的查询意图对应的搜索结果，如果能够在缓存系统找到满足用户需求的信息，则可以直接将搜索结果返回给用户。如果储存在缓存的信息无法满足用户需求，搜索引擎需要调用“网页排序”模块功能，根据用户的查询实时计算哪些网页是满足用户信息需求的，并排序输出作为搜索结果。
- 在网页排序中最重要的两个参考因素中，一个是**内容相似性因素**，即哪些网页是和用户查询密切相关的；另外一个是**网页重要性因素**，即哪些网页是质量较好或者相对重要的，这点往往可以从链接分析的结果获得。





# 第二章：网络爬虫

## 2.4 抓取策略

### 2.4.1 宽度优先遍历策略（Breath First）

- **基本思路**：将新下载网页包含的链接直接追加到待抓取URL队列末尾。
- 这种方法并没有明确提出和使用网页重要衡量标准，知识机械地将新下载的网页抽取链接，并追加到待抓取URL队列中，以此安排URL的下载顺序。

### 2.4.2 非完全PageRank策略（Partial PageRank）

- **基本思路**：对于已经下载的网页，加上待抓取URL队列中的URL一起，形成网页集合，在此集合中记算PageRank计算，计算完成后，将待抓取URL队列里的网页按照PageRank得分由高到低排序，形成的序列就是爬虫接下来应该依次抓取的URL列表。这也是为何称之为”非完全PageRank“的原因。

### 2.4.3 OCIP策略(Online Page Importance Computation)

- 在算法开始之前，每个互联网页面都给与相同的“现金”（cash），每当下载了某个页面P后，P将自己的“现金”平均分配给页面中包含的链接页面，清空自己的“现金”。待抓取的URL则根据自己的现金排序，优先下载现金多的网页。

- OCIP从大的框架上与PageRank思路基本一致，区别在于：PageRank每次需要迭代计算，而OCIP策略不需要迭代过程，所以计算速度远远快于PageRank，适合实时计算使用。

### 2.4.4 大站优先策略

- **基本思路**：以网站为单位来衡量网页的重要性，对于待抓取URL队列中的网页，根据所属网站归类，如果哪个网站等待下载的页面多，则优先下载这些链接。
- 其本质思想倾向于优先下载大型网站，因为大型网站包含更多的页面，网页质量一般较高。



## 2.5 网页更新策略

### 2.5.1 历史参考策略

- 这种方法往往利用泊松过程来对网页的变化进行建模，根据每个网页过去的变动情况，利用模型预测将来何时内容会在此发生变化，以此来指导爬虫的抓取过程。

### 2.5.2 用户体验策略

- 这种更新策略以用户体验为核心，即使本地索引的网页内容是过时的，但是如果不影响用户体验，那么晚些更新这些过时的网页也未尝不可。
- 所以判断一个网页何时更新为好，取决于这个网页的内容变化所带来搜索质量的变化（往往采用搜索结果排名的变化来衡量），影响越大的网页，则应该越快更新。

### 2.5.3 聚类抽样策略

- 聚类抽样策略认为：网页具有一些属性，根据这些属性可以预测其更新周期，具有相似属性的网页，其更新周期也是类似的。为了计算某个类别的更新周期，只需对类别内网页进行采样，以这些被采样网页的更新周期作为类别内所有其他网页的更新周期。
- 与之前叙述的两种方法相比较，这种策略一方面无须为每个网页保存历史信息；另一方面，对于新网页，即使没有历史信息，也可以根据其所属类别来对其进行更新。
- 网页更新周期的属性特征：
  - 静态特征：页面的内容、图片数量、页面大小、链接深度、PageRank值等十几种
  - 动态特征：体验静态特征随着时间的变化情况，比如图片数量的变化情况、入链出链的变化情况。

> - 从爬虫设计角度讲，优秀的爬虫应该具备 **高性能，好的可扩展性、健壮性和友好性**。
> - 从用户体验角度考虑，对爬虫的工作效果评价标准包括：**抓取网页覆盖率、抓取网页时新性和抓取网页重要性**。
> - **抓取策略、网页更新策略、暗网抓取和分布式策略 **是爬虫系统至关重要的4个方面内容，基本决定了爬虫系统的质量和性能。





# 第三章：搜索引擎索引

## 3.1 索引基础

### 3.1.1 单词-文档矩阵

![1556522970406](C:\Users\11101453\AppData\Roaming\Typora\typora-user-images\1556522970406.png)

- 从纵向即文档这个维度来看，每列代表文档包含了哪些单词；从横向即单词这个维度来看，每行代表了哪些文档包含了某个单词。
- 搜索引擎的索引其实就是实现单词-文档矩阵的具体数据结构。可以有不同方式来实现上述概念模型，比如**倒排索引、签名文件、后缀树**等方式。倒排索引是单词到文档映射关系的最佳实现方式。

### 3.1.2 倒排索引基本概念

- **文档（Document）**：一般搜索引擎的处理对象是互联网网页，而文档这个概念要更宽泛些，代表以文本形式存在的存储对象。比如Word、PDF、HTML、XML，再比如一封邮件、一条微博也可以称之为文档。
- **文档集合（Document Collection）**：由若干文档构成的集合称为文档集合。比如海量的互联网网页或者说大量的电子邮件，都是文档集合的具体例子。
- **文档编号（Document ID）**：在搜索引擎内部，会为文档集合内每个文档赋予一个唯一的内部编号，以此编号来作为这个文档的唯一标识，方便内部处理。
- **单词编号（Word ID）**：与文档编号类似，搜索引擎内部以唯一的编号来表征某个单词，单词编号可以作为某个单词的唯一表征。
- **倒排索引（Inverted Index）**：倒排索引是实现单词-文档矩阵的一种具体存储形式。通过倒排索引，可以根据单词快速获取包含这个单词的文档列表。倒排索引主要由两个部分组成：单词词典和倒排文件。
- **单词词典（Lexicon）**：搜索引擎通常的索引单位就是单词，单词词典是由文档集合中出现过的所有单词构成的字符串集合，单词词典内每条索引项记载单词本身的一些信息及指向倒排列表的指针。
- **倒排列表（Posting List）**：<u>倒排列表记载了出现过某个单词的所有文档列表及单词在该文档中出现的位置信息</u>，每条记录称为一个倒排项（Posting）。根据倒排列表，即可获知哪些文档包含某个单词。
- **倒排文件（Inverted File）**：所有单词的倒排列表往往有序地存储在磁盘的某个文件里，这个文件即被称为倒排文件，倒排文件是存储倒排索引的物理文件。

### 3.1.3 倒排索引简单实例

![1556529586265](C:\Users\11101453\AppData\Roaming\Typora\typora-user-images\1556529586265.png)

![1556529608373](C:\Users\11101453\AppData\Roaming\Typora\typora-user-images\1556529608373.png)

![1556529630592](C:\Users\11101453\AppData\Roaming\Typora\typora-user-images\1556529630592.png)

- 如图3-6所示的索引系统除了记录文档编号和单词频率信息外，额外记载了两类信息，即每个单词对应的文档频率信息（对应图3-6的第3列）及单词在某个文档出现的位置信息。
- 以单词“拉斯”为例，其单词编号为8，文档频率为2，代表整个文档集合中有两个文档包含这个单词，对应的倒排列表为（3；1；<4>），（5；1；<4>），其含义为在文档3和文档5出现过这个单词，单词频率都为1，单词“拉斯”在两个文档中出现的位置都是4，即文档中第4个单词是“拉斯”。

![1556529772330](C:\Users\11101453\AppData\Roaming\Typora\typora-user-images\1556529772330.png)

- 有了这个索引系统，搜索引擎可以很方便地响应用户的查询，比如用户输入查询单词“Facebook”，搜索系统查找倒排索引，从中可以读出包含这个单词的文档，这些文档就是提供给用户的搜索结果，而利用单词频率信息、文档频率信息即可对这些候选搜索结果进行排序，计算文档和查询的相似性，按照相似性得分由高到低排序输出，此即为搜索系统的部分内部流程。



## 3.2 单词词典（Lexicon）

- 单词词典是倒排索引中非常重要的组成部分，它用来维护文档集合中出现过的所有单词的相关信息，同时用来记载某个单词对应的倒排列表在倒排文件中的位置信息。在支持搜索时，根据用户的查询词，去单词词典里面查询，就能够获得相应的倒排列表，并以此作为后续排序的基础。
- 为了提高定位单词的速度，需要高效的数据结构来对单词词典进行构建和查找，常用的数据结构包括**哈希加链表结构**和**树形词典结构**。

### 3.2.1 哈希加链表

### 3.3.2 树形结构



## 3.3 倒排列表（Posting List）

- 倒排列表用来记录由哪些文档包含了某个单词。一般在文档集合里会有很多文档包含某个单词，每个文档会记录文档编号（DocID），单词在这个文档中出现的次数（TF）及单词在文档中哪些位置出现过等信息，这样与一个文档相关的信息被称作倒排索引项（Posting），包含这个单词的一系列倒排索引项形成了列表结构，这就是某个单词对应的倒排列表。**即在文档集合中出现过的所有单词及其对应的倒排列表组成了倒排索引**

  ![1556587522396](C:\Users\11101453\AppData\Roaming\Typora\typora-user-images\1556587522396.png)



## 3.4 建立索引

### 3.4.1 两遍文档遍历法（2-Pass In-Memory Inversion）

- **第一遍文档遍历**：第一遍扫描的主要目的是获得一些统计信息，并根据统计信息分配内存等资源，同时建立好单词相对应倒排列表在内存中的位置信息，即主要做哪些资源准备工作。
- **第二遍文档遍历**：第二遍扫描开始真正建立每个单词的倒排列表信息，即对某个单词来说，获得包含这个单词的每个文档的文档ID，以及这个单词在文档中出现次数TF，这样就可以不断填充第一遍扫描所分配的内存空间。第二遍扫描结束，分配的内存空间正好被填充满，而每个单词用指针所指向的内存区域“片段”，其起始位置和终止位置之间的数据就是这个单词对应的倒排列表。

### 3.4.2 排序法（Sort-based Inversion）

- 两遍遍历法在建立索引的过程中，对内存的消耗要求较高，不同的文档集合包含文档数量 大小不同，其所需内存大小是不确定的。当文档集合非常大时，可能因为内存不够，导致无法建立索引。

- 排序法对此作了改进，该方法在建立索引的过程中，始终在内存中分配固定大小的空间，用来存放词典信息和索引的中间结果，当分配的空间被消耗光的时候，把中间结果写入磁盘，清空内存里中间结果所占空间，以用作下一轮存放索引中间结果的储存区。这种方法由于只需要固定大小的内存，所以可以对任意大小的文档集合建立索引。

- 随着新的文档不断被处理完成，存储三元组集合的中间结果所占用的内存会越来越大，词典里包含的新单词也越来越多，当分配的内存定额被占满时，该方法对三元组中间结果进行排序。排序的原则是：

  1. 主键是单词ID，即首先要按照单词ID从小到大排序；
  2. 次键是文档ID，即在相当单词ID的情况下，按照文档ID由小到大排序。

  ![1556592850733](C:\Users\11101453\AppData\Roaming\Typora\typora-user-images\1556592850733.png)

- 通过以上方式，三元组变为有序形式。为了腾出内存空间，将排好序的三元组写入磁盘临时文件中。值得注意的是，在建立索引的过程中，词典是一直存储在内存中的，每次清空内存只是将中间结果写入磁盘。

- 之所以对中间结果进行排序，主要是为了方便后续的处理。因为每一轮处理都会在磁盘产生一个对应的中间结果文件，当所有文档处理完成后，在磁盘中会有多个中间结果文件，为了产生最终的索引，需要将这些中间结果文件合并。

### 3.4.3 归并法（Merge-based Inversion）

- 归并法每次将内存中的数据写入磁盘时，包括词典在内的所有中间结果信息都被写入磁盘，这样内存所有内容都可以被清空，后续建立索引可以使用全部的定额内存。



## 3.5 动态索引

- 这种动态索引中，有3个关键的索引结构**：倒排索引、临时索引**和**已删除文档列表**。

- 如果用户输入查询请求，则搜索引擎同时从倒排索引和临时索引中读取用户查询单词的倒排列表，找到包含用户查询的文档集合，并对两个结果进行合并，之后利用删除文档列表进行过滤，将搜索结果中那些已经被删除的文档从结果中过滤，形成最终的搜索结果，并返回给用户。

  ![1556593924323](C:\Users\11101453\AppData\Roaming\Typora\typora-user-images\1556593924323.png)



## 3.6 索引更新策略

- 动态索引通过在内存中维护临时索引，可以实现对动态文档和实时搜索的支持。但是服务器内存总是有限的，随着新加入系统的文档越来越多，临时索引消耗的内存也会随之增加。当最初分配的内存将被使用完时，要考虑将临时索引的内容更新到磁盘索引中，以释放内存空间来容纳有后续的新进文档。此时要考虑合理有效的索引更新策略。
- 常用的索引更新策略有4种：**完全重建策略、再合并策略、质地更新策略及混合策略**。



## 3.7 查询处理

- 为搜索引擎构建索引，其目的是能更快速地提取与用户查询相关的文档信息，假设搜索引擎已经根据前述章节内容建立好了索引，如何利用倒排索引来相应用户的查询？目前有两种常见的查询处理机制，一种被称作**一次一文档**方式，另外一种被称作**一次一单词**方式。



## 3.8 多字段索引

- 在很多实际的搜索应用领域，搜索引擎索要处理的文档是有一定结构的，即文档包含明确区分的多个字段。搜索引擎需要能够对多字段进行索引，而实现多字段索引有3种方式：**多索引方式、倒排列表方试、扩展列表方式**。



## 3.9 短语查询

- 几个经常连在一起被使用的单词就构成了短语，短语强调单词之间的顺序，有时尽管是同样的单词，顺序点到后会产生完全不同的含义。比如“懂你的”和“你懂的”。
- 搜索引擎支持短语查询，本质问题是如何在索引中维护单词之间的顺序关系或者位置信息。较常见的支持短语查询的技术方法包括：**位置信息索引、双词索引、短语索引**。为了更有效地利用存储和计算资源，也可以将三者结合使用。



## 3.10 分布式索引（Parallel Indexing）

- 当搜索引擎需要处理的文档集合数量非常庞大时，靠单机往往难以承担如此重任，此时需要考虑分布式解决方案，即每台机器维护整个索引的一部分，由多台机器写作来完成索引的建立和对查询的响应。至于多台机器如何分工协作，目前常用的分布式索引方案包括两种：**按文档对索引划分**和**按单词对索引划分**。



> - 倒排索引是搜索引擎用来快速查找包含某个单词的文档集合的数据结构。
>
> - 倒排索引由 **单词词典** 和所有单词对应的 **倒排列表** 构成。
>
> - 倒排列表由倒排列表项构成，一般倒排列表项包含文档ID、单词出现次数和单词在文档中出现位置的信息。而文档ID则采取文档编号差值方式编码。
> - 3种常用的建立倒排索引的方法是：两遍文档遍历法、排序法、归并法。
> - 常用的索引更新策略有4种：完全重建策略、再合并策略、原地更新策略及混合策略。
> - 目前有两种常见的查询处理机制：一次一文档方式、一次一单词方式。
> - 实现多字段索引有3种方式：多索引方式、倒排列表方式、扩展列表方式。
> - 较常见的支持短语查询技术方法包括：位置信息索引、双词索引、短语索引。也可结合使用。
> - 目前常用的分布式索引方案包括两种：按文档对索引划分、按单词对索引划分。





# 第四章：索引压缩

## 4.1 词典压缩

- 上一章介绍了词典的组织方式有两种：哈希加链表和B树形词典结构。在链表内部或B树的叶子节点会储存单词相关信息，一般至少会储存一下3项：单词本身内容、文档频率信息（DF）、指向倒排列表的指针信息。



## 4.2 倒排列表压缩算法

- 单词对应的倒排列表一般记载3类信息：文档编号、词频信息及单词位置序列信息。因此文档编号及单词位置序列是以此递增的，所以通常的做法是存储其差值，而非原始数据。



## 4.3 文档编号重排序（DocID Recording）



## 4.4 静态索引裁剪（Static Index Pruning）





# 第五章：检索模型与搜索排序

- 搜索结果排序是搜索引擎最核心的构成部分，很大程度上决定了搜索引擎的质量好坏及用户接受与否。尽管搜索引擎在实际结果排序时融合了上百种排序因子，但最重要的两个因素还是用户查询和网页的内容相关性及网页链接情况。本章主要介绍：给定用户搜索词，如何从内容相关性的角度对网页进行排序。

- 判断网页内容是否与用户查询有关，这依赖于搜索引擎所采用的检索模型。关于检索模型的研究，从信息检索学科建立之初就一直是研究重点，到目前为止，已经提出了多种各异的模型，其中最重要的集中检索模型：**布尔模型、向量空间模型、概率模型、语言模型、机器学习排序算法**。

- 搜索引擎的核心是判断哪些文档是和用户需求相关的，并按照相关程度排序输出，所以相关度计算是将用户查询和文档内容进行匹配的过程，而检索模型就是用来计算内容相关度的理论基础及核心部件。

- 内容相似性计算框架：

  ![1557022771598](C:\Users\11101453\AppData\Roaming\Typora\typora-user-images\1557022771598.png)

- 这里需要注意的一点是：检索模型理论研究都存在理想化的隐含假设，即假设用户需求已经通过查询非常清晰明确地被表达出来，所以检索模型的任务不牵扯到对用户需求建模。很明显这与事实相距甚远，即使是相同的查询词，不同用户的需求目的可能差异很大，而检索模型对此无能为力。所以可以将检索模型看作是：在用户需求已经很明确地由查询词表征的情况下，如何找出内容相关的文档。如果查询词不能精确代表用户的真实需求，那么无论检索模型再优秀也无济于事，这是为何搜索引擎发展到目前阶段，重点转向了填补用户真实需求和发出的查询词之间的鸿沟的原因，此发展趋势有其必然性。



## 5.1 布尔模型（Boolean Model）

- 布尔模型是检索模型中最简单的一种，其数学基础是集合论。在布尔模型中，文档与用户查询由其包含的单词集合来表示，两者的相似性则通过布尔代数运算来进行判定。
- 布尔模型简单直观，但是正是因为其简单性，导致一些明显的缺点。只要文档满足逻辑表达式，就会被认为是相关的，其他文档被认为是不相关的，即其结果输出是二元的，要么相关要么不相关，至于文档在多大程度上和用户查询相关，能否按照相关程度排序输出搜索结果？这些布尔模型都无能为力，所以无法对搜索结果根据相关性进行排序，其搜索结果过于粗糙。同时，对于普通用户来说，要求其以布尔表达式的方式构建查询，无疑要求过高。（布尔表达式例：苹果 AND (乔布斯 OR iPad2)）



## 5.2 向量空间模型（Vector Space Model）

- 向量空间模型历史悠久，最初由信息检索领域奠基人Salton教授提出，经过想过学科几十年的探索，目前已经是非常成熟和基础的检索模型。向量空间模型作为一种文档表示和相似性计算的工具，不仅仅在搜索领域，在自然语言处理、文本挖掘等诸多其他领域也是普遍采用的有效工具。

### 5.2.1 文档表示

- 作为表示文档的工具，向量空间模型把每个文档看作是由t维特征组成的一个向量，特征的定义可以采取不同方式，可以是单词、词组、N-gram片段等多种形式，最常用的还是以单词作为特征。其中每个特征会根据一定依据计算其权重，这t维带有权重的特征共同构成了一个文档，以此来表示文档的主题内容。

### 5.2.2 相似性计算

- 将文档转换为特征向量后，就可以计算文档之间或者是查询和文档之间的相似性了。对于搜索排序这种任务来说，给定用户输入的查询，理论上应该计算查询和网页内容之间的“相关性”，即文档是否和用户需求相关，之后按照相关程度由高到低排序。向量空间模型将问题做了转换，即以查询和文档之间的**内容相似性**来作为相关性的替代，按照文档和查询的相似性得分由高到低排序作为搜索结果，但是要注意，两者并非等同的概念。

### 5.2.3 特征权重计算

- 文档和查询转换为特征向量时，每个特征都会赋予一定的权值，本节叙述如何对特征计算相应的权值。在向量空间模型里，特征权值的计算框架一般被称作Tf *IDF框架，这一框架考虑的主要计算因子有两个：词频Tf和逆文档频率IDF。
- **词频因子（Tf）**
  - Tf计算因子代表了词频，即一个单词在文档中出现的次数，一般来说，在某个文档中反复出现的单词，往往能够表征文档的主题信息，即Tf值越大，越能代表文档所反映的内容，那么应该给予这个单词更大的权值。
- **逆文档频率因子（IDF）**
  - 词频因子是与文档密切相关的，说一个单词的Tf值，指的是这个单词在某个文档中的出现次数，同一个单词在不同的文档中Tf值很可能不一样。而逆文档频率因子IDF则与此不同，它代表的是文档集合范围的一种全局因子。给定一个文档集合，那么每个单词的IDF值就唯一确定，跟具体的文档无关，**所以IDF考虑的不是文档本身的特征，而是特征单词之间的相对重要性**。



## 5.3 概率检索模型

- 概率检索模型是目前效果最好的模型之一，在TREC等各种检索系统评测会议已经证明了这一点，而且okapi BM25 这一经典概率模型计算公式已经在商业搜索引擎的网页排序中广泛使用。

### 5.3.1 概率排序原理

- 概率检索模型是从概率排序原理推导出来的，所以理解这一原理对于理解概率检索模型非常重要。**概率排序原理的基本思想是**：给定一个用户查询，如果搜索系统能够在搜索结果排序时按照文档和用户需求的相关性由高到低排序，那么这个搜索系统的准确性是最优的。而在文档集合的基础上尽可能准确地对这种相关性进行估计则是其核心。